#import "@preview/qooklet:0.1.1": *
#show: doc => conf(
  title: "线性回归",
  author: "Yāng Xīnbīn",
  footer-cap: "Yāng Xīnbīn",
  header-cap: "极简线性代数",
  lang: "zh",
  outline-on: true,
  doc,
)

= 投影
<投影>

== 正交化后投影
<正交化后投影>

若有 3 个线性无关的向量$𝒂, 𝒃, 𝒄$，则要求其正交向量$𝑨, 𝑩, 𝑪$，再将它们单位化，变为单位正交向量，$𝒒_1 = 𝑨/|𝑨|，𝒒_2 = 𝑩/|𝑩|，𝒒_3 = 𝑪/|𝑪|$。

- 取$𝒂$向量的方向，$𝒂 = 𝑨$；
- 将$𝒃$投影在$𝑨$的法方向上得到$𝑩$，由$𝒆 = 𝒃 - 𝒑$，即

$ 𝑩 = 𝒃 - frac(𝑨^(⊤) 𝒃, 𝑨^(⊤) 𝑨) 𝑨 𝒙 $

- 从$𝒄$中减去其在$𝑨, med 𝑩$上的分量，得到正交与$𝑨, med 𝑩$的$𝑪$

$ 𝑪 = 𝒄 - frac(𝑨^(⊤) 𝒄, 𝑨^(⊤) 𝑨) 𝑨 - frac(𝑩^(⊤) 𝒄, 𝑩^(⊤) 𝑩) 𝑩 $

#tip[
  正交投影即原数据点和投影点连线垂直于投影点所在直线或平面。
]

== 最小二乘法
<最小二乘法>

投影矩阵有 2 个重要性质

- $𝑷 = 𝑷^(⊤)$，投影矩阵是一个对称阵
- $𝑷^2 = 𝑷$，若对一个向量做两次投影，即$𝑷 𝑷 𝒃$，则其结果仍然与$𝑷 𝒃$相同

为什么需要投影？因为有些时候$𝑨 𝒙 = 𝒃$无解，只能求出最接近的那个解。$𝑨 𝒙$总是在$𝑨$的列空间中，而$𝒃$却不一定，故可将$𝒃$变为$𝑨$的列空间中最接近的那个向量，即将无解的$𝑨 𝒙 = 𝒃$变为求有解的$𝑨 hat(𝒙) = 𝒑$，其中，$𝒑$是$𝒃$在$𝑨$的列空间中的投影，$hat(𝒙)$不再是那个不存在的$𝒙$，而是最接近的解。

一般情况下，$𝒃$将会有一个垂直于$𝑨$的分量，有一个在$𝑨$列空间中的分量，投影的作用就是去掉垂直分量而保留列空间中的分量。

举两个极端的例子：

$
  𝒃 ∈ & C(𝑨) ⇒ 𝑷 𝒃 = 𝒃\
  𝒃 ⊥ & C(𝑨) ⇒ 𝑷 𝒃 = 𝟎
$

在第一个极端情况中，若$𝒃 ∈ C(𝑨)$则有$𝒃 = 𝑨 𝒙$。带入投影矩阵$𝒑 = 𝑷 𝒃 = 𝑨(𝑨^(⊤) 𝑨)^(-1) 𝑨^(⊤) 𝑨 𝒙 = 𝑨 𝒙$，得证。在第二个极端情况中，若$𝒃 ⊥ C(𝑨)$则有$𝒃 ∈ N(𝑨^(⊤))$，即$𝑨^(⊤) 𝒃 = 0$，则$𝒑 = 𝑷 𝒃 = 𝑨(𝑨^(⊤) 𝑨)^(-1) 𝑨^(⊤) 𝒃 = 0$，得证。

向量$𝒃$投影后，有$𝒃 = 𝒆 + 𝒑, med 𝒑 = 𝑷 𝒃, med 𝒆 = (𝑰 - 𝑷) 𝒃$，这里的$𝒑$是$𝒃$在$C(𝑨)$中的分量，而$𝒆$是$𝒃$在$N(𝑨^(⊤))$中的分量。

现需要找到距离图中三个点$(1, 1)$ , $(2, 2)$ , $(3, 2)$偏差最小的直线$𝒃 = C + D t$

#figure(
  image("images/ortho-lsq.png", width: 50%),
  caption: "最小二乘投影",
  supplement: "图",
)

根据条件可以得到方程组

$ cases(delim: "{", C + D &= 1, C + 2 D &= 2, C + 3 D &= 2) $

写作矩阵形式

$
  mat(delim: "[", 1, 1; 1, 2; 1, 3)
  mat(delim: "[", C; D) = mat(delim: "[", 1; 2)
$

很明显方程组无解。此时，需要在$𝒃$的三个分量上都增加某个误差$𝒆$，使得三点能够共线，同时使得$𝒒_1^2 + 𝒒_2^2 + 𝒒_3^2$最小，即$|𝑨 𝒙 - 𝒃|^2 = |𝒆|^2$最小。此时向量$𝒃$变为向量

$ 𝒑 = mat(delim: "[", 𝒑_1; 𝒑_2; 𝒑_3) $

在方程组有解的情况下，$𝑨 𝒙 - 𝒃 = 𝟎$，即$𝒃$在$𝑨$的列空间中，误差$𝒆$为零。

#tip[
  若有另一个点，如$(0, 100)$，在本例中该点明显距离别的点很远，最小二乘将很容易被离群的点影响，通常使用最小二乘时会去掉明显离群的点。
]

== 三维投影
<三维投影>

现在来看$ℝ^3$中的情形，将向量$𝒃$投影在平面$𝑨$上。同样的，$𝒑$是向量$𝒃$在平面$𝑨$上的投影，$𝒆$是垂直于平面$𝑨$的向量，即$𝒃$在平面$𝑨$法方向的分量。

设平面$𝑨$的一组基为$𝒂_1, 𝒂_2$，则投影向量$𝒑 = hat(𝒙)_1 𝒂_1 + hat(𝒙)_2 𝒂_2$，即$𝒑 = 𝑨 hat(𝒙)$，这里若求出$hat(𝒙)$，则该解就是无解方程组最近似的解。

现在问题的关键在于找$𝒆 = 𝒃 - 𝑨 hat(𝒙)$，使它垂直于平面，故得到两个方程

$
  cases(delim: "[", 𝒂_1^(⊤)(𝒃 - 𝑨 hat(𝒙)) = 0,
𝒂_2^(⊤)(𝒃 - 𝑨 hat(𝒙)) = 0)
$

将方程组写成矩阵形式

$ mat(delim: "[", 𝒂_1^(⊤); 𝒂_2^(⊤))(𝒃 - 𝑨 hat(𝒙)) = mat(delim: "[", 0; 0) $

即$𝑨^(⊤)(𝒃 - 𝑨 hat(𝒙)) = 0$。

比较该方程与$ℝ^2$中的投影方程，发现只是向量$𝒂$变为矩阵$𝑨$而已，本质上就是$𝑨^(⊤) 𝒆 = 0$。故，$𝒆$在$𝑨^(⊤)$的零空间中（$𝒆 ∈ N(𝑨^(⊤))$）。

再化简方程得$𝑨^(⊤) 𝑨 𝒙 = 𝑨^(⊤) 𝒃$，比较在$ℝ^2$中的情形，$𝑨^(⊤) 𝒂$是一个数字而$𝑨^(⊤) 𝑨$是一个$n$阶方阵，而解出的$x$可以看做两个数字的比值。

现在在$ℝ^3$中

- $hat(𝒙) = (𝑨^(⊤) 𝑨)^(-1) 𝑨^(⊤) 𝒃$；
- $𝒑 = 𝑨 hat(𝒙) = underline(𝑨(𝑨^(⊤) 𝑨)^(-1) 𝑨^(⊤)) 𝒃$，下划线部分就是原来的$frac(𝒂 𝑨^(⊤), 𝑨^(⊤) 𝒂)$；
- 易看出投影矩阵就是下划线部分$𝑷 = 𝑨(𝑨^(⊤) 𝑨)^(-1) 𝑨^(⊤)$。

= 标准方程组
<标准方程组>

现尝试解出$hat(x) = mat(delim: "[", hat(C); hat(D))$与$𝒑 = mat(delim: "[", 𝒑_1; 𝒑_2; 𝒑_3)$

$ 𝑨^(⊤) 𝑨 hat(x) = 𝑨^(⊤) 𝒃 $

$ 𝑨^(⊤) 𝑨 = mat(delim: "[", 3, 6; 6, 14) $

$
  mat(delim: "[", 3, 6; 6, 14) mat(delim: "[", hat(C); hat(D)) = mat(delim: "[", 5; 11)
$

写作形式

$ cases(delim: "{", 3 hat(C) + 16 hat(D) &= 5, 6 hat(C) + 14 hat(D) &= 11) $

称作标准方程组（normal equations）。

为使误差最小，有

$ 𝒒_1^2 + 𝒒_2^2 + 𝒒_3^2 = (C + D -1)^2 + (C + 2 D - 2)^2 + (C + 3 D - 2)^2 $

若使用微积分方法，则需要对该式的两个变量$C, D$分别求偏导数，再令求得的偏导式为零即可，正是刚才求得的标准方程组。

解方程得

$ hat(C) = 2 / 3, hat(D) = 1 / 2 $

则"最优直线"为

$ y = 2 / 3 + 1 / 2 t $

带回原方程组解得

$
  𝒑_1 = 7 / 6, med 𝒑_2 = 5 / 3, med 𝒑_3 = 13 / 6 \
  𝒒_1 = -1 / 6, med 𝒒_2 = 1 / 3, med 𝒒_3 = -1 / 6
$

于是得

$ p = mat(delim: "[", 7/6; 5/3; 13/6), e = mat(delim: "[", -1/6; 1/3; -1/6) $

易看出$𝒃 = 𝒑 + 𝒆$，同时发现$𝒑⋅𝒆 = 𝟎$，即$𝒑 ⊥ 𝒆$。故，误差向量$𝒆$不仅垂直于投影向量$𝒑$，它同时垂直于列空间，如

$ mat(delim: "[", 1; 1; 1), mat(delim: "[", 1; 2; 3) $

= 统计相关

== 数据变换

设$𝑿$为有$n$组数据的数据集矩阵，则其中心化矩阵$𝑿_c$可表示为

$ 𝑿_c = 𝑿 - 𝟏(frac(𝑿^(⊤) 𝟏, n))^(⊤) = (𝟏 - 1 / n 𝟏 𝟏^(⊤))𝑿 $

令$𝑴 = (𝟏 - 1/n 𝟏 𝟏^(⊤))$，可知$𝑴$为对称阵，同时为幂等阵，其对角元均为$1 - 1\/n$，其余元素均为$-1\/n$。

类似地，标准化的矩阵形式为

$ 𝒁_(𝑿) = 𝑿_c 𝑺^(-1) $

其中，$𝑺 = "diag"("diag"(𝜮))^(1/2)$。

== 常见统计量

离差平方和（sum of squared deviations，SSD），又称数据惯性（data's inertia），其定义为

$
  "SSD"(𝑿) &= ∑ norm(𝒙^(⊤) - μ_(𝑿))^2 \
  &= (𝒙^(⊤) 𝑴^(⊤))(𝑴 𝒙) = 𝒙^(⊤) 𝑴 𝒙 = tr(𝑿_c^(⊤) 𝑿)
$

基于上述结果，数据集的方差写作

$ "Var"(𝑿) = 1 / n ∑ (X_i - 𝔼[𝑿])^2 = 1 / n "SSD" $

类似地，数据集的协方差为

$
  "Cov"(𝑿, 𝒀) &= |𝑿 - 𝔼[𝑿]| |𝒀 - 𝔼[𝒀]| \
  &= (𝒙^(⊤) 𝑴^(⊤))(𝑴 𝒚) = 𝒙^(⊤) 𝑴 𝒚 = mat(delim: "[", 𝒙^(⊤); 𝒚^(⊤)) 𝑴 mat(delim: "[", 𝒙, 𝒚)
$

相关系数为

$ "corr" = ρ_(𝑿, 𝒀) = frac("Cov"(𝑿, 𝒀), σ_(𝑿)σ_(𝒀)) $

= Rayleigh 商

Rayleigh 商常用于求二次型的最值

#definition[
  设$𝑨$是$n$阶实对称阵，$𝒙$是$n$维非零列向量，则称

  $ R(𝒙) = frac(𝒙^(⊤) 𝑨 𝒙, 𝒙^(⊤) 𝒙) $

  为 Rayleigh 商。
]

由$𝑨$为实对称阵，则其可对角化，即有$𝑨 = 𝑽 𝜦 𝑽^(⊤)$，于是

$
  𝒙^(⊤) 𝑨 𝒙 = (𝑽^(⊤) 𝒙)^(⊤) 𝜦 (𝑽^(⊤) 𝒙) limits(⟶)^(𝒚 := 𝑽^(⊤) 𝒙) 𝒙^(⊤) 𝑨 𝒙 = 𝒚^(⊤) 𝜦 𝒚
$

又$𝒙^(⊤) 𝒙 = 𝒚^(⊤) 𝒚$，Rayleigh 商可化为如下形式

$ R(𝒙) = frac(𝒚^(⊤) 𝜦 𝒚, 𝒚^(⊤) 𝒚) = frac(∑ λ_i y_i^2, ∑ y_i^2) $

不难看出，该形式类似于$ℓ_2$范数，且$λ_(min) ≤ R(𝒙) ≤ λ_(max)$

= PCA
<PCA>

考虑一个有 5 个点的三维数据集。

$
  X = mat(delim: "[",
  x_0^((0)), x_1^((0)), x_2^((0));
  x_0^((1)), x_1^((1)), x_2^((1));
  x_0^((2)), x_1^((2)), x_2^((2));
  x_0^((3)), x_1^((3)), x_2^((3));
  x_0^((4)), x_1^((4)), x_2^((4)))
$

假设数据已被去均值。检查矩阵乘积$𝑿^(⊤) 𝑿$

$
  𝑿^(⊤) 𝑿 &= mat(delim: "[",
  ∑_(i = 0)^4 (x_0^((i)))^2, ∑_(i = 0)^4 x_0^((i)) x_1^((i)), ∑_(i = 0)^4 x_0^((i)) x_2^((i));
  ∑_(i = 0)^4 x_1^((i)) x_0^((i)), ∑_(i = 0)^4 (x_1^((i)))^2, ∑_(i = 0)^4 x_1^((i)) x_2^((i));
  ∑_(i = 0)^4 x_2^((i)) x_0^((i)), ∑_(i = 0)^4 x_2^((i)) x_1^((i)), ∑_(i = 0)^4 (x_2^((i)))^2)\
  &= mat(delim: "[", σ_00, σ_01, σ_02; σ_10, σ_11, σ_12; σ_20, σ_21, σ_22)
$

故$𝑿^(⊤) 𝑿$是数据集$𝑿$的协方差矩阵。协方差矩阵的特征向量是主轴（principal axes），相应的特征值是数据集的主值（principal values）。
由定义

$ 𝑿 = 𝑼 𝜮 𝑽^(⊤) $

其中，$𝑽$的列是特征向量，奇异值的平方是$𝑿^(⊤) 𝑿$的特征值。故对数据矩阵进行 SVD 可得数据的 PCA。

